2021-12-02 00:00:37,187 config= AMP: False
BASE: ['']
DATA:
  BATCH_SIZE: 16
  BATCH_SIZE_EVAL: 8
  CROP_PCT: 0.875
  DATASET: cifar10
  DATA_PATH: /dataset/imagenet/
  IMAGE_SIZE: 224
  NUM_WORKERS: 2
EVAL: False
LOCAL_RANK: 0
MODEL:
  ATTENTION_DROPOUT: 0.1
  DROPOUT: 0.1
  DROPPATH: 0.1
  NAME: vit_base_patch16_224
  NUM_CLASSES: 1000
  PRETRAINED: Y:\codelab\PaddleViTLearing\PaddleViT\ViT\vit_base_patch16_224
  RESUME: None
  TRANS:
    ATTN_HEAD_SIZE: None
    DEPTH: 12
    EMBED_DIM: 768
    MLP_RATIO: 4.0
    NUM_HEADS: 12
    PATCH_SIZE: 16
    QKV_BIAS: True
  TYPE: ViT
NGPUS: -1
REPORT_FREQ: 100
SAVE: ./output/train-20211202-00-00-37
SAVE_FREQ: 10
SEED: 0
TAG: default
TRAIN:
  ACCUM_ITER: 2
  BASE_LR: 0.003
  END_LR: 0.0005
  GRAD_CLIP: 1.0
  LAST_EPOCH: 0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    MILESTONES: 30, 60, 90
    NAME: warmupcosine
  NUM_EPOCHS: 300
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: AdamW
  WARMUP_EPOCHS: 3
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.3
VALIDATE_FREQ: 100
2021-12-02 00:00:44,545 ----- Pretrained: Load model state from Y:\codelab\PaddleViTLearing\PaddleViT\ViT\vit_base_patch16_224
2021-12-02 00:00:44,546 Start training from epoch 1.
2021-12-02 00:00:44,546 Now training epoch 1. LR=0.001001
2021-12-02 00:00:45,882 Epoch[001/300], Step[0000/3125], Avg Loss: 7.7099, Avg Acc: 0.0000
2021-12-02 00:01:19,732 Epoch[001/300], Step[0100/3125], Avg Loss: 2.9359, Avg Acc: 0.1126
2021-12-02 00:01:55,762 Epoch[001/300], Step[0200/3125], Avg Loss: 2.5826, Avg Acc: 0.1418
2021-12-02 00:02:32,130 Epoch[001/300], Step[0300/3125], Avg Loss: 2.4456, Avg Acc: 0.1586
2021-12-02 00:03:09,128 Epoch[001/300], Step[0400/3125], Avg Loss: 2.3706, Avg Acc: 0.1655
